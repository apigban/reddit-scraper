#!/usr/bin/env python3.7

from getInfo import fetchInput
import requests
import json
import time


def fileOut(subreddit, contentType, response):
    timeStr = time.strftime("%Y%m%d")
    fileName = f"{subreddit}-{contentType}-{timeStr}.json"

    with open(fileName, "a") as jsonFile:
        json.dump(response, jsonFile)
    print(f"Write to {fileName} Successful")


def urlConstructor(subreddit, contentType, initial, final, voteSort):

    baseURL = "https://api.pushshift.io/reddit/search/"
    apiURL = baseURL + "{0}/?subreddit={1}&before={2}&after{3}&sort_type=score&sort={4}&metadata=True".format(contentType, subreddit, initial, final, voteSort)
    print("\n" + 5*"-" + f"Loading URL:  {apiURL}\n")
    return apiURL


#def metaCheck():


#    if contentType == "submissions"
#        apiURL = baseURL + "{0}/?subreddit={1}&before={2}&after{3}&sort_type=score&sort={4}".format(contentType, subreddit, initial, final, voteSort)
#        print(f"Loading URL:  {apiURL}")
#        return apiURL
#
#    elif contentType == "comments"
#        apiURL = baseURL + "{0}/?subreddit={1}&before={2}&after{3}&sort_type=score&sort={4}".format(contentType, subreddit, initial, final, voteSort)
#
#    elif contentType == "all"
#        apiURL = baseURL + "{0}/?subreddit={1}&before={2}&after{3}&sort_type=score&sort={4}".format(contentType, subreddit, initial, final, voteSort)
#
#    else:
#        print("Default Input: Submissions\nUsing Submissions")

def pullPSData(subreddit=None, contentType=None, initial=None, final=None, limit=None, voteSort=None):

    argList = fetchInput()

    apiURL = urlConstructor(argList[0], argList[1], argList[2], argList[3], argList[5])
    response = requests.get(apiURL)
    jsonData = json.loads(response.text)
    #print(type(jsonData))
    fileOut(argList[0], argList[1], jsonData)

pullPSData()
